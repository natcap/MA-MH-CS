---
title: "MA_exposure"
author: "Yingjie"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---


# Setup 
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


### To clear your environment
remove(list = ls())

Sys.setenv(LANG = "en")

## Load directories
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
getwd()
dir.root <- dirname(getwd())
# setwd(dir.root)

getwd()

## Load common packages
source("./code/_pkgs_dirs.R")

## Additional packages
library(googlesheets4)
library(rprojroot)
library(tidyverse)
library(stringr)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)
library(ggpubr)

### packages for meta-analysis
# install.packages("remotes")
# remotes::install_github("guido-s/meta", ref = "develop")
### or an old version that supports R3.6
# url <- 'https://cran.r-project.org/src/contrib/Archive/meta/meta_4.15-0.tar.gz'
# install.packages(url, repos=NULL, type="source")
library(meta)
library(metafor)


today <- format(Sys.time(), "%Y%m%d"); today ## "%Y%m%d%H%M"
```


```{r - functions}
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_indicatorsPro.R')
source('./code/func_clean_tools.R')
source('./code/func_clean_exposure.R')
source('./code/func_clean_effectsize.R')
source('./code/func_clean_nature.R')
source('./code/func_to_sd.R')
source('./code/func_fill_c2_from_c1.R')
source('./code/func_cell_mean.R')

source('./code/func_plot_freq.R')
source('./code/func_alluvial.R')
source('./code/func_ggsave.R')
```


# Data

## Load data from Covidence

```{r}

## load data 
fs <- list.files(path = "./data/0301-MA-input/", pattern = '^df_covidenceFull', full.names = T); 
# fs;

##' select the up-to-date data, which is the second to the last
f1 <- fs[(length(fs)-2)]; f1

##' select the gsheet data file
f2o1 <- fs[(length(fs)-1)]; f2o1
f2o2 <- fs[(length(fs)-0)]; f2o2

df_1 <- readRDS(file = f1) 

df <- df_1 %>%
  dplyr::rename(
    'exposure_type'   = 'Nature exposure type',
    'nature_type'     = "General category of urban nature",
    'nature_quantity' = "Nature quantity measure metric",
    "n_participants"  = "Total number of participants",
    "buffers"         = "Buffer zone size considered for nature exposure measurement",
    "buffers_unit"    = "Buffer zone size's unit",
    'study_design'    = 'Study design',
    "City" = "City and state/province  in which the study conducted"
                  ) %>%
  dplyr::rename_with(~ 'if_standardized', matches("Does this paper employ standardized")) %>%
  dplyr::rename_with(~ 'average_age', matches("Average age ")) %>%
  dplyr::rename_with(~ 'male_percent', matches("Percentage of \\*male\\* participants")) %>%
  dplyr::rename_with(~ 'duration_value', matches("Duration of actual nature exposure")) %>%
  dplyr::rename_with(~ 'duration_unit', matches("The unit of time")) %>%
  dplyr::mutate(id = as.character(id),
                effect_size_indices = `Effect size indices`) %>%
  dplyr::select(1:`Effect size indices`, effect_size_indices, everything()) %>%
  ## remove some columns 
  dplyr::select(-matches("If No")) %>%
  dplyr::mutate(
    # remove text within parenthesis 
    `Health outcome direction` = gsub("\\s*\\([^\\)]+\\)", "", `Health outcome direction`), 
    if_standardized = gsub("\\s*\\([^\\)]+\\)", "", if_standardized), 
    if_standardized = trimws(if_standardized),
    ) %>%
  
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  func_clean_bufferunit(data = ., column_name = 'buffers_unit') %>%
  func_clean_tools(data = ., column_name = 'Tools') %>%
  func_clean_exposure(data = ., column_name = 'exposure_type') %>%
  dplyr::mutate(exposure_type = gsub("；", ";", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("Other: |Other:", "", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("\\s*\\([^\\)]+\\)", "", exposure_type)) %>% # remove text within parenthesis
  
  dplyr::mutate(
    study_design = case_when(
      study_design == 'Randomised controlled trial (RCT)' ~ 'RCT',
      TRUE ~ study_design  ),
    study_design = gsub(" controlled before-after study", "", study_design),
    study_design = gsub(", e.g., ", "", study_design),
    study_design = gsub("\\s*\\([^\\)]+\\)", "", study_design), # remove text within parenthesis 
    study_design = trimws(study_design)) %>%
  
  ## clean messy text in `effect_size_indices`
  func_clean_effectsize(data = ., column_name = 'effect_size_indices') %>%
  dplyr::mutate(
    effect_size_indices = gsub("Other: |Other:", "", effect_size_indices),
    # effect_size_indices = gsub("=.*", "", effect_size_indices), ## remove everything after "="
    effect_size_indices = trimws(effect_size_indices),
    effect_size_indices = case_when(
      effect_size_indices %in% c("coefficient", "coefficients") & if_standardized == "No" ~ "Unstandardized coefficients", 
      effect_size_indices %in% c("coefficient", "coefficients") & if_standardized == "Yes"  ~ "Standardized coefficients", 
      TRUE ~ effect_size_indices)) %>%
  # dplyr::select(1:effect_size_indices, effect_size_name, everything()) %>% ## for data inspection 
  
  ##' clean duration in nature
  func_cell_mean(df = ., column_name = 'duration_value', sep = ';') %>%
  dplyr::mutate(
    duration_unit = gsub("Other: |Other:", "", duration_unit),
    duration_unit = trimws(duration_unit),
    duration_unit = stringr::str_to_sentence(duration_unit),
    
    duration_mins = case_when(
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Minutes' ~ as.numeric(duration_value_mean), 
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Hours' ~ as.numeric(duration_value_mean)*60, 
      ##' assuming 5 days a weeks, 5 hours per day, 4 weeks a month
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Days'  ~ as.numeric(duration_value_mean)*60*5, 
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Weeks' ~ as.numeric(duration_value_mean)*(5*5)*60,
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Months' ~ as.numeric(duration_value_mean)*(5*5)*60*4,
      TRUE ~ NA),
    
    duration_group = case_when(
      is.na(duration_mins)   ~ NA,
      duration_mins <= 15 ~ '<= 15', 
      duration_mins <= 45 ~ '16-45',
      TRUE ~ '>45'),
    duration_group = factor(duration_group, levels = c('<= 15', '16-45', '>45'))
    
    ) %>%
  dplyr::select(1:duration_unit, duration_mins, duration_group, everything()) %>% 
  
  
  ## clean average age, and % of male
  dplyr::mutate(male_percent = gsub("%", "", male_percent)) %>%
  func_cell_mean(df = ., column_name = 'male_percent', sep = ';') %>%
  func_cell_mean(df = ., column_name = 'average_age', sep = ';') %>%
  dplyr::mutate(
    
    gender_group = case_when(
      is.na(male_percent_mean) ~ NA,
      male_percent_mean < 40 ~ "Female > 60%",
      male_percent_mean > 60 ~ "Male > 60%",
      TRUE ~ "Gender Balance"
    ), 
    gender_group = factor(gender_group, levels = c("Female > 60%", 'Gender Balance', "Male > 60%")),
    
    age_group = case_when(
      is.na(average_age_mean) ~ NA,
      average_age_mean < 19 ~ 'Adolescents', # or "teenager" is common in everyday language
      average_age_mean <= 25 ~ 'Young adults',
      average_age_mean < 65 ~ 'Adults',
      TRUE ~ 'Older adults'),
    age_group = factor(age_group, levels = c('Adolescents', 'Young adults', 'Adults', 'Older adults'))
    ) %>%
  
  as.data.frame()
# names(df)

## selected variables for further analysis
cols_keep <- c('Indicator', 'Tools', 'nature_type',  'nature_quantity', 'exposure_type',
               "study_design", 
               'duration_mins', 'duration_group', 
               'male_percent_mean', 'gender_group', 
               'average_age_mean', 'age_group') 


## To add study design tags in Covidence
df_design <- df %>%
  dplyr::select(1:3, study_design) %>%
  dplyr::mutate(
    id = paste0("#", id)
    ) %>%
  arrange(study_design)
writexl::write_xlsx(x = df_design, path = paste0("./data/0301-MA-input/", "df_study_design.xlsx"))


## load data from google sheet 
df_2o1 <- readRDS(file = f2o1) %>%
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  dplyr::mutate(id = gsub('#', '', id),
                id = trimws(id)) %>%
  as.data.frame()

df_2o2 <- readRDS(file = f2o2) %>%
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  dplyr::mutate(id = gsub('#', '', id),
                id = trimws(id)) %>%
  as.data.frame()
```


## Clean data

```{r}

## selected variables for further analysis
cols_keep2 <- c("duration_value", "duration_unit", 'duration_mins', 'male_percent', 'average_age')

df_exp <- df %>%
  dplyr::select(1:7, any_of(cols_keep), matches(paste(cols_keep2, collapse="|"))) %>%
  ## clean text in `exposure_type`
  dplyr::filter(!is.na(exposure_type)) %>%
  as.data.frame()


## unify exposure names
f <- 'https://docs.google.com/spreadsheets/d/11oUNNjsmzC4wvYwcE8Zm_qavww0D6Twxl8UoPve1WOE/edit?usp=sharing'
exposure_tier <- googlesheets4::read_sheet(f, sheet = 'nature_exposure_channels', range = 'A:D') %>%
  dplyr::select(-exposure_type_t3) %>%
  as.data.frame()


df_exp_l <- df_exp %>% 
  ## expand `exposure_type` if there are > 1 exposure types in a study
  expand_col_to_long(data = ., target_col = 'exposure_type') %>%
  ## clean the messy text data due to manual entry 
  func_clean_exposure(data = ., column_name = 'exposure_type') %>%
  dplyr::mutate(
    # exposure_type1 = ifelse(str_detect(exposure_type, regex('duration', ignore_case = T)), 'Time spent in nature', exposure_type),
    exposure_type = ifelse(grepl(x = exposure_type, 'duration|Spending hour|Time spent', ignore.case = T), 
                           'Duration in nature', exposure_type),
    ) %>%
  as.data.frame() %>%
  left_join(., y = exposure_tier, by = 'exposure_type') %>%
  # merge(x=., y = exposure_tier, by = 'exposure_type', all.x = T) %>%
  dplyr::rename('exposure_type_t1' = 'exposure_type') %>%
  
  ## to decide which tier name for the next step analysis
  dplyr::rename('exposure_type'    = 'exposure_type_t2') %>%
  dplyr::select(1:exposure_type_t1, exposure_type, everything())  %>%
  as.data.frame()
```


### stats

```{r **To-do**}
```
  [] 6686 is missing in the data for POMS 
  [x] add data from gsheet
  [] 'L4' needs to be further clarified 
  [] need to separate `In nature - PA` and `In nature - static`
  [] need to separate "single-group pretest-posttest design"(= 1ba) and "independent-groups pretest-posttest design" (= 2ba)
  

```{r exposure}

df_exp_l_stat <- df_exp_l %>% 
  group_by(exposure_type_t1, exposure_type) %>%
  dplyr::count() %>%
  ungroup() %>%
  as.data.frame()

df_exp_l_stat2 <- df_exp_l_stat %>%
  group_by(exposure_type) %>%
  dplyr::summarise_at(c('n'), sum, na.rm = T) %>%
  ungroup() %>%
  dplyr::filter(!is.na(exposure_type)) %>%
  as.data.frame()


plot_freq(data = df_exp_l_stat2, var = 'exposure_type') +
   geom_text(aes(label = n), vjust = .5, hjust = 0)

f <- paste0('stats_nat_exp_', today, '.png')
fname <- paste0(dir.fig, f); fname
func_ggsave(fname = fname, w = 7, h = 4, save_png = T)
```



```{r exposure-tool}
df_exp_l_toolL <- df_exp_l %>%
  dplyr::mutate(Tool = gsub("Other: ", "", Tools),
                ##' remove text within parenthesis 
                Tool = gsub("\\s*\\([^\\)]+\\)", "", Tool)) %>%
  expand_col_to_long(data = ., target_col = "Tool") %>%
  dplyr::mutate(
    Tool = gsub(".*Likert.*|.*likert.*", "Likert scale", Tool),
    # Tool = gsub(";", "", Tool),
    ) %>% 
  func_clean_tools(data = ., column_name = 'Tool') %>%
  dplyr::select(1:Tools, Tool, everything()) %>%
  arrange(Tool)



df_exp_tool_flow <- df_exp_l_toolL %>%
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, 
                       levels = c('exposure_type', 'Tool'), 
                       labels = c('Exposure types', 'Metrics') ),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

width_my <- 1/2
sorted <- T  ## sorted by flow size
sorted <- NA ## default setting, sorted alphabetically 

indicator_n_min <- 5 ## only map indicators with more than 5 times
# Labeling small strata
labele_small <- 5


func_alluvial(data = df_exp_tool_flow, indicator_n_min = 5, width_my = width_my, w_p = 7,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = 'tool_exposure')
```



```{r selected tools ---------------}
### only include the top 3 MH tools ------------------------------------------------------
tool_selected <- c('GHQ-12', 'PANAS', 'POMS', 
                   'STAI', 'SVS',
                   'SF-12', 'SF-36', 'WEMWBS', 'WHO-5',
                   'PSS', 'ROS')
n_tool <- length(unique(tool_selected)); n_tool

# df_exp_tool_flow3 <- df_exp_tool_flow %>%
#   dplyr::mutate(remove = ifelse(dimension == 'Tool' & !layers %in% tool_selected, 0, 1)) %>%
#   dplyr::filter(remove != 0) %>% dplyr::select(-remove)

df_exp_tool_flow3 <- df_exp_l_toolL %>%
  dplyr::filter(Tool %in% tool_selected) %>% 
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, 
                       levels = c('exposure_type', 'Tool'), 
                       labels = c('Exposure types', 'Metrics') ),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

func_alluvial(data = df_exp_tool_flow3, indicator_n_min = 5, width_my = width_my, w_p = 7,
              labele_small = 5,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = paste0('tool', n_tool, '_exposure'))
```


```{r type-exposure-tool}

df_type_exp_tool <- df_exp_l_toolL %>%
  dplyr::filter(Tool %in% tool_selected) %>% 
  func_clean_nature_type(data=., column_name = 'nature_type', aggregate = T) %>%
  expand_col_to_long(data = ., target_col = 'nature_type') %>%
  group_by(nature_type, exposure_type, Tool) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type', 'nature_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, 
                       levels = c('nature_type', 'exposure_type', 'Tool'), 
                       labels = c('Nature type', 'Exposure type', 'Metric') ),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

df_type_exp_tool %>% func_alluvial(
  data = ., indicator_n_min = 5, width_my = width_my, w_p = 7,
  labele_small = 5,
  show_y_ticks = F, 
  filename.prefix = '', filename.postfix = paste0('tool', n_tool, '_exposure_natureType'))
```



```{r age group}
min(df$average_age_mean, na.rm = T) # 10.8

p_age <- df %>% 
  ggplot() +
  geom_histogram(aes(x = average_age_mean, fill = age_group), binwidth = 2) +
  # scale_x_continuous()
  theme_bw()+
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent"))
p_age
```



```{r gender %}
p_gender <- df %>% 
  ggplot() +
  geom_histogram(aes(x = male_percent_mean, fill = gender_group), binwidth = 5) +
  theme_bw()+
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent"))

p_gender
```



```{r duration}
df %>% 
  dplyr::filter(duration_mins < quantile(.$duration_mins, probs = 0.99, na.rm = T) ) %>%
  ggplot() +
  geom_histogram(aes(x = duration_mins), binwidth = 10) +
  theme_bw()

# df %>% 
#   # dplyr::filter(duration_mins < quantile(.$duration_mins, probs = 0.85, na.rm = T) ) %>%
#   dplyr::filter(duration_mins < 120 ) %>%
#   ggplot() +
#   geom_histogram(aes(x = duration_mins), binwidth = 5) +
#   scale_x_continuous(breaks = c(15, 20, 30, 60)) +
#   theme_bw()


p_duration <- df %>% 
  # dplyr::filter(duration_mins < quantile(.$duration_mins, probs = 0.85, na.rm = T) ) %>%
  dplyr::filter(duration_mins < 120 ) %>%
  ggplot() +
  geom_histogram(aes(x = duration_mins, fill = duration_group), binwidth = 10) +
  scale_x_continuous(breaks = c(15, 30, 45, 60)) +
  theme_bw() +
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent"))

p_duration
```


```{r stat - combine - SM, warning=FALSE}
ggarrange(p_age, p_gender, p_duration)

fname <- paste0(dir.fig, paste0('stats_subgroup_', today, '.png')); #fname
func_ggsave(fname = fname, w = 7, h = 7, save_png = T)
```



```{r nature_quantity}

df_q <- df_exp %>%
  dplyr::select(1:2, Indicator, Tools, nature_type, nature_quantity, 
         # buffer, buffer_unit, 
         exposure_type) %>%
  dplyr::filter(!nature_quantity %in% c('', NA, 'NA'))


## nature quantity metrics - plan to look into
pat_q <- "NDVI|EVI|Percent|SVG"

df_q_ndvi <- df_q %>%
  dplyr::filter(str_detect(nature_quantity, pattern = regex(pat_q, ignore_case = TRUE)))

df_q_ndvi_ <- df_q_ndvi %>%
  dplyr::select(Tools, nature_quantity) %>%
  expand_col_to_long(data = ., target_col = 'Tools') %>%
  expand_col_to_long(data = ., target_col = 'nature_quantity') %>%
  dplyr::filter(str_detect(nature_quantity, pattern = regex(pat_q, ignore_case = TRUE))) %>%
  group_by(Tools, nature_quantity) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tools', 'nature_quantity')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

indicator_n_min <- 5 ## only map indicators with more than 5 times
# Labeling small strata
labele_small <- 3


func_alluvial(data = df_q_ndvi_, indicator_n_min = 2, width_my = width_my, w_p = 7,
              show_y_ticks = T, 
              filename.prefix = '', filename.postfix = 'tool_quantity')
```


## Prepare data for MA

### * Coefficient-based outcomes ---

```{r}
tool_selected


###' subset papers that examined `exposure_type_i`
###' 

func_exp_subset <- function(df, exposure_type_i, mh_tool) {
  
  ## get paper id
  exp_sub <- df_exp_l %>%
    dplyr::filter(exposure_type %in% exposure_type_i)
  exp_sub_id <- unique(exp_sub$id)

  ## subset based paper id
  exp_sub_df <- df %>%
    dplyr::filter(id %in% exp_sub_id) %>%
    dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
    
    ## subset cols -----------------------------------------------------------------------
    dplyr::select(id:`Effect size indices`, effect_size_indices, 
                  everything()) %>%
    dplyr::select(id:Country, 
                  all_of(cols_keep), 
                  n_participants, buffers, buffers_unit,
                  effect_size_indices:ncol(.)) %>%
    dplyr::select(-c(Title:meet_criteria)) %>%
    dplyr::select(-contains(c('Please specify the tables', 'Additional comments'))) %>%
    as.data.frame()
  
  return(exp_sub_df)
  
}


# df_exp_tool_flow3 <- df_exp_l_toolL %>%
#   dplyr::filter(Tool %in% tool_selected) %>% 
```


#### - GHQ-12
```{r}
mh_tool           <- "GHQ-12"

# exposure_type_i   <- 'L1 - neighborhood/residential exposure'
exposure_type_i   <- c('Residential')
effect_size_ind_i <- c('coef')
  

## test 
# df_test <- df %>%
#   dplyr::mutate(effect_size_indices = `Effect size indices`) %>%
#   func_clean_effectsize(data = .) %>%
#   dplyr::select(effect_size_indices, `Effect size indices`) %>%
#   dplyr::mutate(len = str_length(effect_size_indices)) %>%
#   arrange(desc(len)) %>%
#   as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_ghq <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)


## for RA/Carl
f <- gsub('rds', 'csv', f); f
readr::write_csv(x = exp_sub_df, file = f)
```



#### - SF-12, SF-36
```{r}
mh_tool <- c("SF-12", "SF-36")

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')
effect_size_ind_i <- c('coef')
  

## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_sf <- exp_sub_df



## save for later use
## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - WEMWBS
```{r}
mh_tool <- c('WEMWBS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')
effect_size_ind_i <- c('coef')
  

## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_WEMWBS <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```

#### - WHO-5
```{r}
mh_tool <- c('WHO-5')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')
effect_size_ind_i <- c('coef')
  

## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_who5 <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```



#### - PSS - obs
```{r}
mh_tool <- c('PSS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')
effect_size_ind_i <- c('coef')
  

## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_pss <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '_obs.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```



### * MD-focused outcomes ---

```{r}
effect_size_ind_i <- c(
  "D",
  "d",
  'Raw values',
  "Mean_pre_post")
```


#### - PANAS
```{r}
mh_tool <- "PANAS"

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - Static', 'In nature - PA')
 
exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool) 
sub_panas <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```



#### - POMS
```{r}
mh_tool <- "POMS"

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - Static', 'In nature - PA')

###' subset papers that examined `exposure_type_i`
exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_poms <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - PSS - exp
```{r}
mh_tool <- c('PSS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA', 'Interacting')

## test 
df_test <- df %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

df_test %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
exp_sub_df %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)
sub_pss <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - ROS
```{r}
mh_tool <- c('ROS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')


## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_ros <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - STAI
```{r}
mh_tool <- c('STAI')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')


## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)

sub_stai <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - SVS
```{r}
mh_tool <- c('SVS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')


## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)

sub_svs <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - DASS-21
```{r}
mh_tool <- c('DASS-21')

unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA', 'Interacting')


## test 
df_test <- df %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

df_test %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
exp_sub_df %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)
sub_dass <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```



## Format data

### Load input data

  Now, each paper can include data from multiple models, and they are presented in columns. 
We need to put all data on models in rows. 

```{r}

# source('./code/010s1_loop_format_data.R')


##' 1. when 'PSS' is mainly used in `obs` studies
mh_tool_obs <- c('GHQ-12', 'SF-12', 'SF-36', 'WEMWBS', 'WHO-5', 'PSS'); design <- 'obs'
mh_tool_exp <- c('PANAS', 'POMS', 'ROS', 'STAI', 'SVS');         design <- 'exp'


##' 2. when 'PSS' is mainly used in `exp` studies
mh_tool_obs <- c('GHQ-12', 'SF-12', 'SF-36', 'WEMWBS', 'WHO-5'); design <- 'obs'
mh_tool_exp <- c('PANAS', 'POMS', 'ROS', 'STAI', 'SVS', 'PSS', 'DASS-21');  design <- 'exp'
```



### Format data

#### * One-by-one
```{r - wide to long format}

##' Test code for formatting one model
# exp_sub_mod1 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 1 ") & !contains("measurement", ignore.case = TRUE))
# 
# exp_sub_mod11 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 11 "))


##' loop all 20 models (in the Covidence form, we have 20 rows for data extraction)
exp_sub_l <- data.frame()
for (i in 1:20) {
  # print(i)
  mod_id <- paste0("Model ", i, " ")
  exp_sub_dfi <- exp_sub_df %>%
    dplyr::select(id, `Study ID`,
                  all_of(cols_keep),
                  contains("effect_size_indices"), 
                  `Health outcome direction`, 
                  n_participants, buffers, buffers_unit,
                  ##' loop a model by selecting the column names 
                  ##' but need to exclude data from table 3 (with column names that contain key word 'measurement')
                  starts_with(mod_id) & !contains("measurement", ignore.case = TRUE)) %>%
    dplyr::mutate(model_id = i) %>%
    dplyr::select(id, effect_size_indices, model_id, `Health outcome direction`, everything())
  
  ##' remove model id so that they can be rbind (require the same column names)
  colnames(exp_sub_dfi) <- sub(mod_id, "", colnames(exp_sub_dfi))
  ##' Remove part of string after "."
  colnames(exp_sub_dfi) <- gsub("\\..*","",colnames(exp_sub_dfi))
  
  ##' Repair duplicate names - specify your own name repair function
  exp_sub_dfi <- exp_sub_dfi %>%
    as_tibble(., .name_repair = make.unique) %>%
    as.data.frame()
  
  exp_sub_l <- rbind(exp_sub_l, exp_sub_dfi)
}

rm(exp_sub_dfi)
```



```{r - clean names from table 1/2, include=FALSE}
##' _o1:  table option 1
##' _o2:  table option 2
##' _cov: extracted data stored in Covidence 
##' _gs:  extracted data stored in gsheet (the extended tables)

## for data extracted in table option 1 --------------------------------------------------
exp_sub_l_o1_cov <- exp_sub_l %>%
  dplyr::select(id:t_value) %>%
  as.data.frame()
name1 <- names(exp_sub_l_o1_cov) %>%
  gsub('\\.1|\\.2', '', .) %>%
  gsub('Other covariates that are beyond the baseline', 'Other_covariates_o1', .)
name1.1 <- name1[1: (which(name1 == 'MH_indicator')-1)]
name1.2 <- name1[which(name1 == 'MH_indicator'):length(name1)] %>% paste0(., '_o1')
names(exp_sub_l_o1_cov) <- c(name1.1, name1.2) 
names(exp_sub_l_o1_cov)
```


```{r - bind Covidence and gsheet data}

exp_sub_l_o1_gs <- df_2o1 %>%
  dplyr::select(-c("group_id", "Study ID", "Reviewer", "Reviewer_id")) %>%
  dplyr::mutate(id = gsub('#', '', id))

# exp_sub_l_o1_cov_ <- exp_sub_l_o1_cov %>%
#   dplyr::select(id, model_id, Other_covariates_o1:ncol(.))


unique(exp_sub_l_o1_gs$id)

exp_sub_l_o1_gs_add <- exp_sub_l_o1_cov %>%
  ##' get the paper list that stored in gsheet
  ##' use the id list to get general data (section 1-3) in the 
  ##'   Covidence-based data, which has also been subset based on specific MH tools
  dplyr::filter(id %in% unique(exp_sub_l_o1_gs$id)) %>%
  dplyr::distinct(id, .keep_all = T) %>%
  dplyr::select(1:exp_mean, -model_id) %>%
  
  ##' join the *Covidence data* to *gsheet-based table*
  right_join(., exp_sub_l_o1_gs, by = 'id') %>%
  dplyr::select(1:effect_size_indices, model_id, everything()) %>%
  ##' if effect_size_indices is NA, this means these papers are not related to 
  ##'   the MH tool we are working on 
  dplyr::filter(!is.na(effect_size_indices)) %>%
  as.data.frame()
  

# names(exp_sub_l_o1_cov)
# names(exp_sub_l_o1_gs_add)
names(exp_sub_l_o1_gs_add) <- names(exp_sub_l_o1_cov)

## bind covidence and gsheet data
exp_sub_l_o1 <- rbind(exp_sub_l_o1_cov, exp_sub_l_o1_gs_add) %>%
  dplyr::mutate(model_id = as.character(model_id))



## for data extracted in table option 2 --------------------------------------------------
exp_sub_l_o2_cov <- exp_sub_l %>%
  dplyr::select(id, model_id, Notes:Notes.1) %>%
  dplyr::select(-c(Notes:t_value))
name2 <- names(exp_sub_l_o2_cov) %>%
  gsub('\\.1|\\.2', '_o2', .) %>%
  gsub('Other covariates that are beyond the baseline', 'Other_covariates', .)
names(exp_sub_l_o2_cov) <- name2  
# names(exp_sub_l_o2_cov)


exp_sub_l_o2_gs <- df_2o2 %>%
  dplyr::select(-c("group_id", "Study ID", "Reviewer", "Reviewer_id")) %>%
  ## only include the selected `mh_tool`
  dplyr::filter(id %in% unique(exp_sub_df$id)) %>%
  as.data.frame()
# names(exp_sub_l_o2_cov)
# names(exp_sub_l_o2_gs)
names(exp_sub_l_o2_gs) <- names(exp_sub_l_o2_cov)

## bind covidence and gsheet data
exp_sub_l_o2 <- rbind(exp_sub_l_o2_cov, exp_sub_l_o2_gs) %>%
  dplyr::mutate(model_id = as.character(model_id))



##' further combine data from the combined table option 1 and option 2 -------------------
##' 
##' 1. get the shared/common info, and unique columns for tables o1 and o2
tab_o1 <- exp_sub_l_o1 %>%
  dplyr::select(id, model_id, exp:ncol(.))
tab_o2 <- exp_sub_l_o2

non_shared_cols <- setdiff(names(tab_o1), 'id')

tab_share <- exp_sub_l_o1 %>%
  dplyr::select(-any_of(non_shared_cols)) %>%
  dplyr::distinct_all()

##' 
##' 2. merge table option 1 and table option 2 as a combined table
##'     given the number of models for option 1 could be different from the number of 
##'     models for option 2, we need to use `full_join()`, 
##'     instead of `left_join()`, in order to keep all the data
##'     
tab_comb <- full_join(tab_o1, tab_o2, 
                      by = c("id", "model_id")) %>%
  ##' 3. merge shared info to the combined table
  left_join(., tab_share, 
            by = c('id')) %>%
  ## move the common data columns to the most left side 
  dplyr::select(any_of(names(tab_share)), everything()) %>%
  dplyr::select(id, model_id, everything())


exp_sub_comb <- tab_comb %>%
  func_clean_indicatorsPro(data = ., column_name = 'Indicator') %>%
  func_clean_indicatorsPro(data = ., column_name = 'MH_indicator_o1') %>%
  func_clean_indicatorsPro(data = ., column_name = 'MH_indicator_o2') %>%
  func_clean_buffer(data = ., column_name = 'buffer_o1') %>%
  func_clean_buffer(data = ., column_name = 'buffer_o2') %>%
  
  func_clean_tools(data = ., column_name = 'MH_tool_o1') %>%
  func_clean_tools(data = ., column_name = 'MH_tool_o2') %>%
  
  func_clean_exposure(data = ., column_name = 'exposure_o1') %>%
  func_clean_exposure(data = ., column_name = 'exposure_o2') %>%
  
  as.data.frame()

## remove these two df after merging
# rm(exp_sub_l_o1, exp_sub_l_o2)
```



```{r - add geodata}
f <- paste0('./data/0301-MA-input/id_region_match.rds'); f
id_region <- readRDS(f) %>%
  dplyr::select(id, Region) %>%
  dplyr::mutate(id = as.character(id))

exp_sub_comb_update <- exp_sub_comb %>%
  left_join(., id_region, by = 'id') %>%
  dplyr::select(id, Region, everything())
```



```{r - clean numeric values}
### clean up the negative sign "-" in data
test <- exp_sub_comb_update %>%
  dplyr::filter(id %in% c(387)) ## take the character from this paper

m <- gsub(' ', '', test$Mean)
m <- "−0.23"
sign <- m[1] %>% substr(., 1, 1)
sign
# mm <- gsub(sign, '-', m)
# mm
# as.numeric(mm)
rm(test)
sign <- paste(sign, '−', sep = '|')


func_clean_number <- function(data, column_name){
  
  # Check if the specified column exists in the data frame
  if (!(column_name %in% colnames(data))) {
    stop("Column not found in the data frame.")
  }
  
  column_name_new <- column_name %>%
    gsub("Control_",   "c_", .) %>%
    gsub("Treatment_", "e_", .) %>%
    as.character() %>%
    str_to_lower()
    
    
  # Manipulate the specified column using multiple pipes
  d <- data %>%
    dplyr::mutate(
      !!column_name_new := !!sym(column_name),
      !!column_name_new := as.character(!!sym(column_name_new)),
      !!column_name_new := gsub(sign, "-", !!sym(column_name_new)),
      !!column_name_new := gsub(" ", "", !!sym(column_name_new)), 
      !!column_name_new := str_squish(!!sym(column_name_new)),
      !!column_name_new := trimws(!!sym(column_name_new)),
      !!column_name_new := as.numeric(!!sym(column_name_new))
    ) %>%
    dplyr::select(1:!!sym(column_name), !!column_name_new, everything()) %>%
    as.data.frame()
  return(d)
}

### test code
# exp_sub_comb_clean1 <- exp_sub_comb_update %>%
#   func_clean_number(column_name = 'Mean')

exp_sub_comb_clean <- exp_sub_comb_update %>%
  dplyr::filter(!is.na(Mean) | !is.na(Treatment_Mean) | !is.na(Treatment_Mean)) %>%
  
  ##' clean the special character "-" in text
  func_clean_number(data = ., column_name = 'Mean') %>%
  func_clean_number(data = ., column_name = 'SD') %>%
  func_clean_number(data = ., column_name = 'SE') %>%
  func_clean_number(data = ., column_name = 'CI_95_lower') %>%
  dplyr::rename('ci95lower' = 'ci_95_lower') %>%
  
  func_clean_number(data = ., column_name = 'Control_Mean') %>%
  func_clean_number(data = ., column_name = 'Control_SD') %>%
  func_clean_number(data = ., column_name = 'Control_SE') %>%
  func_clean_number(data = ., column_name = 'Control_CI95lower') %>%
  
  func_clean_number(data = ., column_name = 'Treatment_Mean') %>%
  func_clean_number(data = ., column_name = 'Treatment_SD') %>%
  func_clean_number(data = ., column_name = 'Treatment_SE') %>%
  func_clean_number(data = ., column_name = 'Treatment_CI95lower') %>%
  
  dplyr::mutate(
    study_label = paste(id, model_id, sep = '_'), # `Study ID`, 
    ) %>%
  dplyr::select(study_label, everything()) %>%
  
  ## check and tidy sample size (N) ------------------------------------------------------
  dplyr::mutate(
    n_participants = str_squish(n_participants) %>% trimws(.) %>% as.numeric(.),
    
    ## for o1
    N = str_squish(N) %>% trimws(.),
    N = gsub(" ", "", N), 
    ## use "n_participants" to fill data gaps of N in data extraction tables
    n = ifelse(is.na(N) & !is.na(n_participants), n_participants, N),
    n = as.numeric(n),
  ) %>%
  dplyr::select(1:N, n, everything()) %>%
  
  dplyr::mutate(
    ## for o2
    Control_N   = str_squish(Control_N)   %>% trimws(.) %>% as.numeric(.),
    Treatment_N = str_squish(Treatment_N) %>% trimws(.) %>% as.numeric(.),
    c_n = case_when(
      !is.na(c_mean) & is.na(Control_N) & !is.na(Treatment_N) ~ Treatment_N,
      !is.na(c_mean) & is.na(Control_N) &  is.na(Treatment_N) & !is.na(n_participants) ~ n_participants,
      TRUE ~ Control_N
    ),
    e_n = case_when(
      !is.na(e_mean) & is.na(Treatment_N) & !is.na(Control_N) ~ Control_N,
      !is.na(e_mean) & is.na(Treatment_N) &  is.na(Control_N) & !is.na(n_participants) ~ n_participants,
      TRUE ~ Treatment_N
    )
  ) %>%
  ## keep new created variables next to its similar ones
  dplyr::select(1:Control_N, c_n, Treatment_N, e_n, study_label, everything()) %>%

  ## convert SE, and CI to `SD` ----------------------------------------------------------
  func_all_to_sd(data = ., table_option = 'o1') %>%
  func_all_to_sd(data = ., table_option = 'o2') %>%
  
  func_clean_nature_quant(data = ., column_name = 'nature_quantity_o1') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity_o2') %>%
  
  ## fill blanks using data from the column `Tools`, but only if there is only one tool in `Tools`
  func_fill_c2_from_c1(data = ., to_column = "MH_tool_o1", from_column = 'Tools') %>%
  func_fill_c2_from_c1(data = ., to_column = "MH_tool_o2", from_column = 'Tools') %>%
  dplyr::mutate(MH_tool_o1 = case_when(MH_tool_o1 == "GHQ" ~ "GHQ-12", TRUE ~ MH_tool_o1),
                MH_tool_o2 = case_when(MH_tool_o2 == "GHQ" ~ "GHQ-12", TRUE ~ MH_tool_o2)) %>%
  
  ## `func_fill_c2_from_c1()` is adapted from `func_fill_tool` (deleted) but can replace the latter
  func_fill_c2_from_c1(data = ., to_column = 'exposure_o1', from_column = "exposure_type") %>%
  func_fill_c2_from_c1(data = ., to_column = 'exposure_o2', from_column = "exposure_type") %>%
  func_fill_c2_from_c1(data = ., to_column = 'nature_type_o1', from_column = "nature_type") %>%
  func_fill_c2_from_c1(data = ., to_column = 'nature_type_o2', from_column = "nature_type") %>%
  
  ## clean text in nature-related columns 
  func_clean_nature_type(data = ., column_name = 'nature_type_o1', aggregate = F) %>%
  func_clean_nature_type(data = ., column_name = 'nature_type_o2', aggregate = F) %>%
  ## merge selected nature types
  func_clean_nature_type_customize(data = ., column_name = 'nature_type_o1') %>%
  func_clean_nature_type_customize(data = ., column_name = 'nature_type_o2') %>%
  
  dplyr::select(id, model_id, study_label, Region,
                all_of(cols_keep), 
                effect_size_indices:Mean, mean, 
                # CI_95_lower, ci95lower, 
                everything()) %>%
  arrange(effect_size_indices, id, model_id) %>%
  as.data.frame()


# names(exp_sub_comb_clean)
unique(exp_sub_comb_clean$MH_tool_o1) %>% cat('\nUnique MH_tool_o1: ', ., '\n')
unique(exp_sub_comb_clean$MH_tool_o2) %>% cat('\nUnique MH_tool_o2: ', ., '\n')

unique(exp_sub_comb_clean$id) %>% length() %>% cat('\n', ., 'unique papers for', mh_tool, '\n')
```




```{r - unify outcome direction}
unique(exp_sub_comb_clean$effect_size_indices)


##' Unify the direction of MH outcomes, mainly apply to the following tools --------------
##'   - GHQ-12 
##'   - SF
##'   - WHO-5
##'   - WEMWBS
exp_sub_mods <- exp_sub_comb_clean %>%
  dplyr::mutate(
    MH_direction_o1 = as.numeric(MH_direction_o1),
    MH_direction_o2 = as.numeric(MH_direction_o2),
    
    ##' fix missing data in `MH_direction_o`
    MH_direction_o1 = case_when(
      is.na(MH_direction_o1) & `Health outcome direction` == "Lower is better"  ~ -1, 
      is.na(MH_direction_o1) & `Health outcome direction` == "Higher is better" ~ 1, 
      TRUE ~ MH_direction_o1),
    
    MH_direction_o2 = case_when(
      is.na(MH_direction_o2) & `Health outcome direction` == "Lower is better"  ~ -1, 
      is.na(MH_direction_o2) & `Health outcome direction` == "Higher is better" ~ 1, 
      TRUE ~ MH_direction_o2),
    
    ## change coefficient-related outcomes to positive direction 
    mean = case_when(
      effect_size_indices %in% c("Standardized coefficients", "Unstandardized coefficients", "coefficient") &
        MH_direction_o1 == -1 ~ -mean,
      effect_size_indices == 'or' &
        MH_direction_o1 == -1 ~ 1-(mean-1),
      TRUE ~ mean),
    
    ci95lower = ifelse(MH_direction_o1 == 1, -ci95lower, ci95lower),
    ) %>%
  # dplyr::select(1:`Health outcome direction`, MH_direction_o1, everything()) %>%
  as.data.frame()
```




```{r - subset `effect_size_indice`}
##' further filter data based on MH tools ------------------------------------------------
source('./code/func_clean_indicatorsPro.R')

cat('\n\n')
unique(exp_sub_comb_clean$MH_tool_o1) %>% cat('unique MH_tool_o1:', ., '\n')
unique(exp_sub_comb_clean$MH_tool_o2) %>% cat('unique MH_tool_o2:', ., '\n')

if ( all(mh_tool %in% mh_tool_obs) ) {
  exp_sub_mods_coef <- exp_sub_mods %>%
    dplyr::filter((str_detect(pattern = paste(effect_size_ind_i, collapse = "|"), string = effect_size_indices))) %>%
    dplyr::filter(MH_tool_o1 %in% mh_tool | MH_tool_o2 %in% mh_tool) %>%
    func_clean_indicator_level2(data = ., column_name = 'MH_indicator_o1') %>%
    func_clean_indicator_level2(data = ., column_name = 'MH_indicator_o2') %>%
    as.data.frame() 
  
  } else if ( all(mh_tool %in% mh_tool_exp) ) {
    exp_sub_mods_md <- exp_sub_mods %>%
      dplyr::filter((str_detect(pattern = paste(effect_size_ind_i, collapse = "|"), string = effect_size_indices))) %>%
      dplyr::filter(MH_tool_o1 %in% mh_tool | MH_tool_o2 %in% mh_tool) %>%
      func_clean_indicator_level2(data = ., column_name = 'MH_indicator_o1') %>%
      func_clean_indicator_level2(data = ., column_name = 'MH_indicator_o2') %>%
      as.data.frame()
    ## make a copy of the data
    # exp_sub_mods_panas <- exp_sub_mods_md

  } else {
    print('...')
  }
```



```{r - print & check}
### print and double-check results =======================================================
if ( any(mh_tool %in% mh_tool_obs) ) {
  exp_sub_mods_print <- exp_sub_mods_coef
} else {
  exp_sub_mods_print <- exp_sub_mods_md
}

## how many unique papers?
length(unique(exp_sub_mods_print$id)) %>% cat('\nFor', mh_tool, '--------------- \n In total, there are', ., 'unique papers.')
nrow(exp_sub_mods_print) %>% cat('\n In total, there are', ., 'studies. \n\n')

##' unique tools 
unique(exp_sub_mods_print$MH_tool_o1) %>% cat('unique MH_tool_o1:', ., '\n')
unique(exp_sub_mods_print$MH_tool_o2) %>% cat('unique MH_tool_o2:', ., '\n\n')

##' inspect data for further cleaning --------------------------------------------------
unique(exp_sub_mods_print$MH_indicator_o1) %>% sort() %>% 
  paste(., collapse = '\n\t', sep = '') %>%
  cat('MH_indicator_o1:\n\t', ., '\n\n');
unique(exp_sub_mods_print$MH_indicator_o2) %>% sort() %>% 
  paste(., collapse = '\n\t', sep = '') %>%
  cat('MH_indicator_o2:\n\t', ., '\n\n');


unique(exp_sub_mods_print$nature_type_o1) %>% sort()
unique(exp_sub_mods_print$nature_type_o2) %>% sort()
```
  
  

#### * Batch

```{r - 1. batch one}
##' 1. Choose one as input --------------------------------
##' 
# f <- paste0('./data/0301-MA-input/', 'sub_ghq.RData')   # `mh_tool`, `exposure_type_i`, `effect_size_ind_i`, `exp_sub_df`
f <- paste0('./data/0301-MA-input/', 'sub_PANAS.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_poms.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_PSS.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_ROS.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_SVS.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_STAI.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_DASS-21.RData')

load(f)
source('./code/010s1_loop_format_data.R')
f.c <- gsub('.rds|.RData', '_cleaned.csv', f); f.c
readr::write_csv(x = exp_sub_mods_print, file = f.c)
```


```{r  - 2. loop all}
##' 1. loop all -----------------------------------
##' 
fs <- list.files(path = './data/0301-MA-input/', pattern = '^sub_.*.RData', full.names = T) %>% sort()
fs
for (f in fs) {
  print(basename(f))
  # exp_sub_df <- readRDS(f)
  load(f)
  ##
  source('./code/010s1_loop_format_data.R')
  f.c <- gsub('.rds|.RData', '_cleaned.csv', f); f.c
  readr::write_csv(x = exp_sub_mods_print, file = f.c)
}

```



*Meta-analysis*

  --> Ref to `010a_MA_intro.Rmd` for more background knowledge. 

```{r functions}
# Calculate s_pooled - pooled standard deviation (SD) of both groups
sd_pooled <- function(n1, n2, sd1, sd2) {
  sd_p <- sqrt(
    ( ((n1-1)*sd1^2) + ((n2-1)*sd2^2) )/
      ((n1-1)+(n2-1))
  )
  return(sd_p)
}

# Calculate the standard error (SE)
se_pooled <- function(n1, n2, sd1, sd2) {
  se_p <- sd_pooled(n1, sd1, n2, sd2) * sqrt((1/n1)+(1/n2))
  return(se_p)
}
```
