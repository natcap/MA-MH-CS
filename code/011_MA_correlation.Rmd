---
title: "Untitled"
author: "Yingjie"
date: "`r Sys.Date()`"
output: html_document
---


# Setup 
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


### To clear your environment
remove(list = ls())


## Load common packages
<<<<<<< HEAD
source(file = "./code/_pkgs_dirs.R")

## Additional packages
library(googlesheets4)
library(rprojroot)
library(tidyverse)
library(stringr)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)
library(ggpubr)

### packages for meta-analysis
# install.packages("remotes")
# remotes::install_github("guido-s/meta", ref = "develop")
### or an old version that supports R3.6
# url <- 'https://cran.r-project.org/src/contrib/Archive/meta/meta_4.15-0.tar.gz'
# install.packages(url, repos=NULL, type="source")
library(meta)
library(metafor)

```


```{r - functions}
source('./code/func_plot_freq.R')
source('./code/func_alluvial.R')
=======
source("./code/_pkgs_dirs.R")
library(tidyr)
```



```{r - functions}
source('./code/func_clean_indicatorsPro.R')
>>>>>>> 9e645176f3239a0f5eef2d4ad545fe7ef5f1a6f8
source('./code/func_ggsave.R')
```



# Meta-analysis

## Correlation

  Correlations are restricted in their range, and it can introduce bias when we estimate the standard error for studies with a small sample size (Alexander, Scozzaro, and Borodkin 1989).
  
  The (Pearson or product-moment) correlation coefficient quantifies the direction and strength of the (linear) relationship between two quantitative variables and is therefore frequently used as the outcome measure for meta-analyses. Two alternative measures are a bias-corrected version of the correlation coefficient and Fisher's r-to-z transformed correlation coefficient.
  
**Convert to standard correlation coefficient**
  Double-check and make sure all the coefficients have been converted to Pearson correlation coefficient, which range between [-1, 1]. If a paper use a different coefficient, we'll need to use functions in `func_convert_to_r.R` to do the conversion first before using the data for MA. It can be tricky when dealing with regression coefficients, but here is a best practice: 
  First, we need to clarify what regression models are used. 
    - Simple Linear Regression (SLR)   -- with only one predictor, or one independent variable.
    - Multiple Linear Regression (MLR) -- with two or more predictors. 
  Then, 
  * if a paper report standardized regression coefficients, the coefficients can be used directly, regardless of SLR or MLR; 
  * if a paper report non-standardized regression coefficients,
    - for SLR, we can use either `func_regression_R2_to_r()` or `func_regression_t_to_r()`;
    - for MLR, given that R2 is not for one particular predictor, but for all the predictors, it might not be accurate to use `func_regression_R2_to_r()`. However, if they report the `t-value` for each predictor, it would be better we use `func_regression_t_to_r()` to estimate `r`





## Load data & coefficient conversion

 - [] need to fix data that are out of range later (search "???")
 - []

```{r}

dir.input <- paste0(dirname(getwd()), '/meta-analysis-nature-health/data/0301-MA-input/')

## 
mh_tool_obs <- c('GHQ-12', 'SF-12', 'SF-36', 'WEMWBS', 'WHO-5', 'PSS'); design <- 'obs'


# Add wildcard after each element and collapse into a single regex pattern
pattern <- paste("sub_(", paste(paste0(mh_tool_obs, ".*"), collapse = "|"), ")_cleaned.csv$", sep = "")
files  <- list.files(path = dir.input, pattern = pattern, full.names = T) %>% unique() %>% sort()
# Exclude files containing "PSS_cleaned", which belongs to experimental study data
filtered_files <- grep("PSS_cleaned", files, invert = TRUE, value = TRUE)
filtered_files


## Read and combine all filtered files into a single data frame
library(data.table)  # For fread()
data_obs_combined <- do.call(rbind, lapply(filtered_files, function(file) {
  fread(file)  # Replace fread() with read.csv() or read.delim() if needed
}))


unique(data_obs_combined$MH_tool_o1)

data_obs_cor <- data_obs_combined %>%
  dplyr::filter(!is.na(mean)) %>%
  dplyr::filter(MH_tool_o1 %in% mh_tool_obs) %>%
  # dplyr::filter(mean <=1 & mean >=-0.6) %>% ## ???
  # dplyr::mutate() %>%
  dplyr::mutate(
    
    ##' fix `nature_type_o1`
    nature_type_o1 = case_when(
        str_to_sentence(nature_type_o1) %in% c("Other natural space/element", "Public natural spaces") ~ "Greenspace", 
        T ~ nature_type_o1),
    
    ##' fix `nature_quantity_o1`
    nature_quantity_o1 = ifelse(is.na(nature_quantity_o1), nature_quantity, nature_quantity_o1),
    nature_quantity_o1 = case_when(
      nature_quantity_o1 %in% c('Percentage green space', 'Percentage Green Space', 
                                'Percentage of Green space', 'Percentage of green', 
                                'Green space proportion', 'Green space coverage') ~ 'Percentage of greenspace',
      nature_quantity_o1 %in% c('Percentage of blue', 'percentage cover of all fresh- and saltwater bodies', 
                                'proportion of water area', 'Blue space coverage') ~ 'Percentage of bluespace',
      T ~ nature_quantity_o1),
    
    ##' fix `MH_indicator_o1`
    MH_indicator_o1 = ifelse(is.na(MH_indicator_o1), Indicator, MH_indicator_o1),
    MH_indicator_o1 = str_to_title(MH_indicator_o1)) %>%
  
  dplyr::filter(!grepl("how much nature|distance to|frequency|presence|Green view|Binary|Area of parks|Amount of|POS accessibility|POS area|Home Year Vegetation|Per capita", nature_quantity_o1, ignore.case = TRUE)) %>%
  dplyr::filter(!grepl("Tree cover|tree canopy", nature_quantity_o1, ignore.case = TRUE)) %>%
  dplyr::filter(!is.na(nature_quantity_o1)) %>%
  dplyr::filter(!study_label %in% c('984_1')) %>% # exclude as the `nature_quantity_o1` == 'Coastal proximity'
  dplyr::filter(!id %in% c('121')) %>% # exclude because it took low % greenspace as the reference group 
  as.data.frame()

data_obs_cor_check <- data_obs_cor %>%
  select(study_label, nature_quantity, nature_quantity_o1, 
         nature_type, nature_type_o1,
         everything()) %>%
  arrange(nature_quantity_o1)

MH_tool_o1_list <- unique(data_obs_cor$MH_tool_o1); MH_tool_o1_list
```



```{r - data desc}
# names(data_obs_cor)

unique(data_obs_cor$MH_tool_o1)
unique(data_obs_cor$MH_indicator_o1) ## need to fix the NA if any

unique(data_obs_cor$nature_quantity)
unique(data_obs_cor$nature_quantity_o1)

```


```{r - nature_quantity}
source('./code/func_alluvial.R')

df_q <- data_obs_cor %>%
  dplyr::select(1:2, Indicator, Tools, MH_tool_o1, nature_type, nature_quantity, nature_quantity_o1, 
         # buffer, buffer_unit, 
         exposure_type) %>%
  dplyr::filter(!nature_quantity_o1 %in% c('', NA, 'NA'))


df_q_filter <- df_q %>%
  dplyr::select(nature_quantity_o1, MH_tool_o1) %>%
  group_by(MH_tool_o1, nature_quantity_o1) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('nature_quantity_o1', 'MH_tool_o1')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  dplyr::mutate(dimension = factor(x = dimension, levels = c('nature_quantity_o1', 'MH_tool_o1'))) %>%
  as.data.frame()

indicator_n_min <- 2 ## only map indicators with more than n times
# Labeling small strata
labele_small <- 1


func_alluvial(data = df_q_filter, 
              first_column = 'nature_quantity_o1', 
              indicator_n_min = indicator_n_min, 
              width_my = 0.5, w_p = 7,
              show_y_ticks = T, add_flow_label = F,
              filename.prefix = '', filename.postfix = 'tool_quantity_OBS')
```



```{r - NDVI only}

data_obs_ndvi <- data_obs_cor %>%
  dplyr::filter(nature_quantity_o1 %in% c('NDVI')) %>%
  select(-c(model_id, Tools, Indicator, nature_type, nature_quantity, exposure_type,
            Mean, effect_size_indices_raw, exp,
            duration_mins, duration_group, `p value`, N, n_participants,
            Other_covariates_o2:Notes_o2)) %>%
  # select(buffers, buffers_unit, buffer_o1, everything()) %>%
  mutate(
    buffer_o1 = as.numeric(buffer_o1), 
    buffer_o1 = case_when(
      is.na(buffer_o1) ~ as.numeric(buffers), 
      !is.na(buffer_o1) & buffer_o1 < 10 & buffers_unit == 'km' ~ buffer_o1 * 1000,
      T ~ buffer_o1)) %>%
  select(1:mean, effect_size_indice_o1, everything()) %>%
  select(1:MH_ind, MH_indicator_o1, MH_tool_o1, everything())


obs_ndvi_ghq <- data_obs_ndvi %>%
  dplyr::filter(MH_tool_o1 == 'GHQ-12')

obs_ndvi_who <- data_obs_ndvi %>%
  dplyr::filter(MH_tool_o1 == 'WHO-5')


cat('# of GHQ-12 unique papers:', length(unique(obs_ndvi_ghq$id)))
cat('# of WHO-5  unique papers:', length(unique(obs_ndvi_who$id)))
```


## MA

**R packages for MA**
  
  There are two packages that can be used for MA. 
  1. *meta*
  
  2. *metafor*
    - ri, the vector with the raw correlation coefficients
    - ni, the corresponding sample sizes. 

    The options for the measure argument are then:
      * "COR" for the raw correlation coefficient,
      * "UCOR" for the raw correlation coefficient corrected for its slight negative bias (based on equation 2.3 in Olkin & Pratt, 1958),
      * "ZCOR" for Fisher's r-to-z transformed correlation coefficient (Fisher, 1921).
      
      
```{r - use `meta`}
m.cor <- meta::metacor(
  data = data_obs_cor,
  cor = mean, 
  n = n,
  studlab = study_label,
  fixed = FALSE,
  random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  title = "Health and Wellbeing")
summary(m.cor)


```


```{r - use `metafor`}
# load the metafor package
library(metafor)

dat <- metafor::escalc(data=data_obs_cor, measure="ZCOR", ri=mean, ni=n)
study_label <- paste(dat$id, dat$model_id, sep = '_')


res <- metafor::rma(yi, vi, data=dat, slab = study_label)
res
predict(res, transf=transf.ztor) ## ztor: z to r

### outlier/influence diagnostics
# par(mar=c(5,6,4,2))
# plot(influence(res), cex=0.8, las=1)
```


## Heterogeneity

  If the confidence interval around τ^2 does not contain zero, it indicates that some between-study heterogeneity exists in our data. 
  The value of τ is x, meaning that the true effect sizes have an estimated standard deviation of SD=x, expressed on the scale of the effect size metric.
  
  A look at the second line reveals that I^2= 63% and that H (the square root of H2) is 1.64. This means that more than half of the variation in our data is estimated to stem from true effect size differences. Using Higgins and Thompson's "rule of thumb", we can characterize this amount of heterogeneity as moderate to large.
  
  Here is how we could report the amount of heterogeneity we found in our example:

<<<<<<< HEAD
  *The between-study heterogeneity variance was estimated at ^τ2 = 0.08 (95%CI: 0.03-0.35), with an I2 value of 63% (95%CI: 38-78%). The prediction interval ranged from g = -0.06 to 1.21, indicating that negative intervention effects cannot be ruled out for future studies.*
=======
```
  The between-study heterogeneity variance was estimated at ^τ2 = 0.08 (95%CI: 0.03-0.35), with an I2 value of 63% (95%CI: 38-78%). The prediction interval ranged from g = -0.06 to 1.21, indicating that negative intervention effects cannot be ruled out for future studies.
```
>>>>>>> 9e645176f3239a0f5eef2d4ad545fe7ef5f1a6f8


### Forest plot

```{r - forest - meta}
width_forestPlot = 40
height_cm <- nrow(data_obs_cor)/1.1

f <- paste0('./figures/', 'forest_cor/', paste(MH_tool_o1_list, collapse = "_"), '_all_', today, '_meta.png'); f
png(filename = f, 
    # width = 3000, height = 3000, units = "px", pointsize = 22,
    width = width_forestPlot, height = height_cm, units = "cm", res = 100);
  
  
p_forest <- meta::forest(
  m.cor, 
  # sortvar = TE,
  # prediction = TRUE, 
  # print.tau2 = T,
  addpred=TRUE, 
  header=TRUE, 
  digits=2, 
  print.I2 = T,
  pooled.totals=T,
  overall = T,
  overall.hetstat = T,
  
  col.by = "black",
  col.square = "black",
  col.inside = "black",
  col.square.lines = "black",
  shade=TRUE,
  layout = "RevMan5",
  slab = study_label, shade=TRUE,
  leftlabs = c("Study ID", "g", "SE"))
# p_forest

dev.off()

```


  https://wviechtb.github.io/metafor/reference/forest.rma.html
```{r - forest - metafor, warning=FALSE}
### forest plot --------------------------------------------------------------------------
# forest(res)
# forest(res, addpred=TRUE, header=TRUE)
# print(forest(res, addpred=TRUE, header=TRUE))
xlim_custmize = c(-1,1)

f <- paste0('./figures/', 'forest_cor/', paste(MH_tool_o1_list, collapse = "_"), '_all_', today ,'.png'); f
png(file=f, 
    # width = 3.5, height = 4, units = 'in', 
    width = 1000, height = 1000, units = "px", pointsize = 22,
    # res = 200
    ) 
meta::forest(res, 
             addpred=TRUE, header=TRUE, 
             digits=2, 
             print.I2 = T,
             layout = "RevMan5", 
             xlim=xlim_custmize, slab = study_label, shade=TRUE)
dev.off() 



# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label) # showweights=TRUE
# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp)
# #' optional argument to specify a function to transform the x-axis labels and annotations (e.g., atransf=exp)
# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp, at=log(c(.6, .8, 1, 1.2, 1.4)))
```




* NOT in use
```{r - subgroup - to be fixed, eval=FALSE, include=FALSE}
# a little helper function to add Q-test, I^2, and tau^2 estimate info
mlabfun <- function(text, res) {
   list(bquote(paste(.(text),
      " (Q = ", .(formatC(res$QE, digits=2, format="f")),
      ", df = ", .(res$k - res$p),
      ", p ", .(metafor:::.pval(res$QEp, digits=2, showeq=TRUE, sep=" ")), "; ",
      I^2, " = ", .(formatC(res$I2, digits=1, format="f")), "%, ",
      tau^2, " = ", .(formatC(res$tau2, digits=2, format="f")), ")")))}

# set up forest plot (with 2x2 table counts added; the 'rows' argument is
# used to specify in which rows the outcomes will be plotted)
# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label)
forest(res, 
       addpred=TRUE, 
       slab = study_label,
       # xlim=c(-16, 4.6), at=log(c(0.05, 0.25, 1, 4)), 
       # atransf=exp,
       # ilab=cbind(dat$tpos, dat$tneg, dat$cpos, dat$cneg),
       # ilab.xpos=c(-9.5,-8,-6,-4.5), cex=0.90, 
       # ylim=c(-1, 27),            ## add extra space in plot
       order=dat$nature_quantity, 
       # rows=c(3:4,9:15,20:23),    ## set positions
       mlab=mlabfun("RE Model for All Studies", res),
       psize=1, header="Author(s) and Year")

# set font expansion factor (as in forest() above) and use a bold font
op <- par(cex=0.90, font=2)


# switch to bold italic font
par(font=4)

# add text for the subgroups
text(-16, c(24,16,5), pos=4, c("Systematic Allocation",
                               "Random Allocation",
                               "Alternate Allocation"))

# set par back to the original settings
par(op)

# fit random-effects model in the three subgroups
res.s <- rma(yi, vi, subset=(nature_quantity=="NDVI"), data=dat)
res.r <- rma(yi, vi, subset=(nature_quantity=="Percentage of greenspace"),     data=dat)
res.a <- rma(yi, vi, subset=(nature_quantity=="Other: Percentage of greenspace; Percentage of bluespace; presence of a garden"),  data=dat)

# add summary polygons for the three subgroups
addpoly(res.s, row=18.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.s))
addpoly(res.r, row= 7.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.r))
addpoly(res.a, row= 1.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.a))

# fit meta-regression model to test for subgroup differences
res <- rma(yi, vi, mods = ~ nature_quantity, data=dat)

# add text for the test of subgroup differences
text(x = -16, y = -1.8, pos=4, cex=0.90, bquote(paste("Test for Subgroup Differences: ",
     Q[M], " = ", .(formatC(res$QM, digits=2, format="f")), ", df = ", .(res$p - 1),
     ", p = ", .(formatC(res$QMp, digits=2, format="f")))))
```



```{r - subgroup data}
add_subgroup_analysis <- T

subgroup_select <- 'exposure_o1'
subgroup_select <- 'nature_type_o1'; subgroup_label = 'Nature type'

subgroups <- c(
  # 'subgroup_design', ## ?? [] need to fix NAs in the column -> revise `subgroup_selected`
  'exposure_o1',
  'nature_type_o1', 
  'Region'
  # 'age_group', 'gender_group', 'duration_group'
  )

for (subgroup_select in subgroups) {
  
  print(subgroup_select)
  
  ma_cor_data <- data_obs_cor %>%
    dplyr::filter(!is.na(exposure_o1)) %>%
    dplyr::mutate(subgroup_selected = !!sym(subgroup_select)) 
  
  unique(ma_cor_data$exposure_o1)
  unique(ma_cor_data$nature_type_o1)
  ind_name <- unique(ma_cor_data$MH_indicator_o1)
  
  ma_cor <- meta::metacor(
    data = ma_cor_data,
    cor = mean, 
    n = n,
    studlab = study_label,
    fixed = FALSE,
    random = TRUE,
    method.tau = "REML",
    tau.common = TRUE,
    hakn = TRUE,
    title = "Health and Wellbeing")
  
  
  h_just <- nrow(ma_cor_data)/50
  h_just <- if_else(h_just>1, h_just, 2)
  
  ## update the MA by adding subgroup analysis ---------------------------------------------
  if (add_subgroup_analysis == T) {
    ma_cor <- ma_cor %>%
      # dplyr::mutate(subgroup_selected = !!sym(subgroup_select)) %>%
      # dplyr::filter(!is.na(subgroup_selected)) %>%
      update(., subgroup = subgroup_selected)
    
    test.effect.subgroup.random_para = TRUE
    postfix_subgroup <- paste0("subgroup_", subgroup_select)
    height_cm <- height_cm
      
    } else {
      test.effect.subgroup.random_para = F
      postfix_subgroup <- ""
    }
  
  
  
  ## extract the overall effect size data to a dataframe ===================================
  
  ma_result.overall <- data.frame()
  ma_result.subgroup <- data.frame()
  
  ### 1. overall model data ----------------------------------------------------------------
  ma_cor.df <- data.frame(
    tool = paste(MH_tool_o1_list, collapse = ";"), 
    ind_sub = paste(ind_name, collapse = ";"),
    group_name = '',
    subgroup = 'Overall',
    es.mean = ma_cor$TE.random,
    es.lower= ma_cor$lower.random,
    es.upper= ma_cor$upper.random,
    pval    = ma_cor$pval.random %>% round(., digits = 10),
    I2      = as.numeric(ma_cor$I2) %>% round(., digits = 2),
    p_subgroup = NA,
    ## Number of studies
    n_study = ma_cor$k.all,
    ## Number of observations
    n_obs   = sum(ma_cor$n, na.rm = T)
  ) %>%
    dplyr::mutate(
      p.star  = case_when(pval < 0.001 ~ '***',
                        pval < 0.01 ~ '**',
                        pval < 0.05 ~ '*',
                        T ~ ''),
    )
  ma_result.overall <- rbind(ma_result.overall, ma_cor.df)
  
  ### 2. subgroup model data ---------------------------------------------------------------
  if (add_subgroup_analysis == T) {
    ma_cor.df.subgroup <- data.frame(
      tool = paste(MH_tool_o1_list, collapse = ";"), 
      ind_sub = paste(ind_name, collapse = ";"), 
      group_name = subgroup_select,
      subgroup = names(ma_cor$TE.common.w),
      es.mean = as.numeric(ma_cor$TE.random.w),
      es.lower= as.numeric(ma_cor$lower.random.w),
      es.upper= as.numeric(ma_cor$upper.random.w),
      pval    = as.numeric(ma_cor$pval.random.w) %>% round(., digits = 10),
      I2      = as.numeric(ma_cor$I2.w) %>% round(., digits = 2),
      p_subgroup = as.numeric(ma_cor$pval.Q.b.random) %>% round(., digits = 10),
      ## Number of studies
      n_study = as.numeric(ma_cor$k.all.w),
      ## Number of observations
      n_obs   = NA
    ) %>%
      dplyr::mutate(
        p.star  = case_when(pval < 0.001 ~ '***',
                          pval < 0.01 ~ '**',
                          pval < 0.05 ~ '*',
                          T ~ ''),
      )
    ma_result.subgroup <- rbind(ma_result.subgroup, ma_cor.df.subgroup)
  }
  
  
  ## save MA result 
  cat('\n')
  fname <- paste0('./data/0302-MA-output/', 
                  paste('ma_result.overall_', paste(MH_tool_o1_list, collapse = "_"), '.rds', sep = '')); fname
  saveRDS(ma_result.overall, file = fname)
  
  if (add_subgroup_analysis == T) {
    fname <- paste0('./data/0302-MA-output/', 
                    paste('ma_result.subgroup', paste(MH_tool_o1_list, collapse = "_"), subgroup_select, '.rds', sep = '_')); 
    print(basename(fname))
    saveRDS(ma_result.subgroup, file = fname)
  }
  
}
```



```{r - subgroup plot - detail}
## forest plot ---------------------------------------------------------------------------

f <- paste0('./figures/', 'forest_cor/', paste(MH_tool_o1_list, collapse = "_"), '_', postfix_subgroup, '_',  today, '_meta.png'); f
png(filename = f, 
    # width = 3000, height = 3000, units = "px", pointsize = 22,
    width = width_forestPlot/2, height = height_cm*h_just, units = "cm", res = 100)

p_forest <- meta::forest(
  ma_cor, 
  # sortvar = TE,
  # prediction = TRUE, 
  # print.tau2 = T,
  addpred=TRUE, 
  header=TRUE, 
  digits=2, 
  print.I2 = T,
  pooled.totals=T,
  overall = T,
  overall.hetstat = T,
  
  col.by = "black",
  col.square = "black",
  col.inside = "black",
  col.square.lines = "black",
  shade=TRUE,
  layout = "RevMan5",
  slab = study_label, shade=TRUE,
  leftlabs = c("Study ID", "g", "SE"))
# p_forest

dev.off()
```





```{r - subgroup plot - overall}
source('./code/func_plot_ma.R')
source('./code/func_color_bygroup.R')

mh_tool_ls <- c('GHQ-12')
mh_tool_ls <- c('GHQ-12', "SF-12", "SF-36", 'WEMWBS', 'WHO-5', 'PSS')

fs <- list.files(path = "./data/0302-MA-output/", 
                 pattern = paste('^ma_result.*_', mh_tool_ls, collapse = '|', sep = ''), 
                 full.names = T);
cat('\n This', length(fs), 'files will be included:\n')
print(fs)

ma_result_all <- data.frame()
for (f in fs) {
  d <- readRDS(file = f) 
  ma_result_all <- rbind(ma_result_all, d)
}


func_color_bygroup(df = ma_result_all, column_name = 'subgroup')
v_just <- length(unique(ma_result_all$subgroup))/5*0.05


##
## pool all data together  ---------------------------------------------------------------
data <- ma_result_all %>%
  # dplyr::filter(ind_sub %in% ind_for_presentation) %>%
  dplyr::filter(subgroup == 'Overall') 
x_limit_max <- max(abs(data$es.lower), abs(data$es.upper), na.rm = T) * 1.2

data %>%
  plot_effect_size_overall(data = ., 
                           color_var = 'tool', 
                           text_size = 11,
                           show_legend = T) +
  scale_x_continuous(limits = c(-x_limit_max, x_limit_max)) +
  theme(legend.position.inside = c(0.85, 0.9),
        # legend.spacing.y = unit(0, 'cm'),
        legend.spacing.x = unit(0.2, 'cm'),
        legend.key.size = unit(0.2, 'cm'),
        plot.margin = margin(t=0, r=0, b=0, l=0, "pt")) +
  guides(color = guide_legend(title="MH Tools"))
```


```{r - subgroup plot - by group}
subgroups <- unique(ma_result_all$group_name); subgroups
subgroups <- subgroups[subgroups!='']
ind_sub_levels <- unique(ma_result_all$ind_sub); ind_sub_levels


library(RColorBrewer)
# Define the original Dark2 palette with maximum colors
dark2_palette  <- brewer.pal(8, "Dark2")
paired_palette <- brewer.pal(12, "Paired")
combined_palette <- c(dark2_palette, paired_palette)
# Create a color interpolation function
color_interpolator <- colorRampPalette(dark2_palette)


for (subgroup_select in subgroups) {

  ## subset data
  ma_result_all_sub <- ma_result_all %>%
    dplyr::filter(subgroup != 'Overall',
                  group_name == subgroup_select) %>%
    dplyr::filter(ind_sub %in% ind_sub_levels)
  
  n <- unique(ma_result_all_sub$subgroup) %>% length()
  # # Generate more colors, e.g., 20 colors
  # more_colors <- color_interpolator(n)
  more_colors <- combined_palette[1:n]

  ma_result_all_sub %>%
    plot_effect_size_overall(
      data = ., 
      color_var = 'subgroup', 
      subgroup = 'subgroup', 
      facet_bygroup = T, 
      facet_scales = 'free',
      text_size = 11,
      add_gradient_bg = F,
      show_legend = T) +
    theme(
      legend.position = c(2/3, 0.15),
      legend.spacing.y = unit(0, 'cm'),
      legend.spacing.x = unit(0, 'cm'),
      legend.key.size = unit(0.01, 'cm'), 
      legend.key.width = unit(0.01, 'cm'),
      legend.justification = "left", 
      legend.title=element_text(size=8.5, face = 'bold'),
      legend.text=element_text(size=8),
      plot.margin = margin(0, 0, 0, 0, "pt"), 
          ) +
    facet_wrap(~ind_sub, ncol = 3) +
    scale_colour_manual(values = more_colors) +
    guides(color = guide_legend(title=subgroup_label))
  
  
  
  fname <- paste0(dir.fig, 'es_comb_css_', subgroup_select, '_', postfix_subgroup, '_', today, '.png'); fname
  func_ggsave(fname, w = 6, h = 5.5, save_png = T)

}
```




  A drapery plot plots a confidence curve for each study, as well as for the average effect. The x-axis shows the effect size metric. 
  The drapery plot is available in the R package meta

```{r}

# meta::drapery(
#   x = m.cor,
#   labels = "id",
#   type = "pval",
#   legend = FALSE)
```



### Funnel plot for publication bias

  Given our assumptions, and in the case when there is no publication bias, all studies would lie symmetrically around our pooled effect size (the vertical line in the middle), within the form of the funnel. 
  
  When *publication bias* is present, we would assume that the funnel would look asymmetrical, because only the small studies with a large effect size very published, while small studies without a significant, large effect would be missing.
  
  We can see in the plot that while some studies have statistically significant effect sizes (the gray areas), others do not (white background). 
  
  - https://cjvanlissa.github.io/Doing-Meta-Analysis-in-R/smallstudyeffects.html
  
  - https://wviechtb.github.io/metafor/reference/funnel.html
  
```{r}
### funnel plot --------------------------------------------------------------------------
# funnel(res)
# funnel(res, ylim=c(0,.08), las=1)
funnel(res, ylim=c(0,.08), las=1, digits=list(2L,2), legend=TRUE)

## trim and fill method
funnel(trimfill(res), # , side = 'left'
       las=1, ylim=c(0,.08), digits=list(2L,2), 
       # cex=1.2,
       legend=TRUE)

# res
# trimfill(res)

## contour-enhanced funnel plot
# funnel(dat$yi, dat$vi, yaxis="seinv", ## "seinv" for the inverse of the standard errors
#        # xlim=c(-.5, .5),
#        # ylim=c(10, 200), 
#        xaxs="i", yaxs="i", las=1, 
#        level=c(.10, .05, .01), 
#        shade=c("white", "gray55", "gray85"), ## pink -- not significant 
#        legend=TRUE, 
#        # back="grey90",
#        hlines=NULL, ylab="Precision (1/se)")

f <- paste0('./figures/', 'funnel_cor_', paste(MH_tool_o1_list, collapse = "_"), '_', today ,'.png'); f
png(file=f, 
    width = 1000, height = 1000, units = "px", pointsize = 22) 
funnel(
  # trimfill(res, side = 'right'),
  res,
  las=1, ylim=c(0,.08), digits=list(2L,2),
  level=c(.10, .05, .01),
  shade=c("white", "gray50", "gray65"), ## pink -- not significant
  legend=TRUE,
  back="grey90",
  hlines=NULL)
dev.off() 

```







```{r - auto-report, eval=FALSE, include=FALSE}
### reporter() function
dir.report <- paste0('./figures/'); dir.report
metafor::reporter(res, dir = dir.report)

# reporter(res, format="pdf", 
#          dir = paste0(dir.root, '/figures/'), 
#          filename = 'report_metafor.PDF')
#          
# reporter(res, format="word")

### add an outlier
# dat$yi[6] <- 2.5
# res <- rma(yi, vi, data=dat)
# reporter(res)
```




